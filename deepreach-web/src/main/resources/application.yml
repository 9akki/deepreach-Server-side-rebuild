server:
  port: 8080
  servlet:
    context-path: /api
    encoding:
      charset: UTF-8
      enabled: true

spring:
  application:
    name: deepreach

  profiles:
    active: dev

  servlet:
    multipart:
      max-file-size: 10MB
      max-request-size: 10MB

  # 数据源配置
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.cj.jdbc.Driver
    druid:
      initial-size: 5
      min-idle: 5
      max-active: 20
      max-wait: 60000
      time-between-eviction-runs-millis: 60000
      min-evictable-idle-time-millis: 300000
      validation-query: SELECT 1
      test-while-idle: true
      test-on-borrow: false
      test-on-return: false
      pool-prepared-statements: true
      max-pool-prepared-statement-per-connection-size: 20
      filters: stat,wall,log4j2
      connection-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
      web-stat-filter:
        enabled: true
        url-pattern: "/*"
        exclusions: "*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*"
      stat-view-servlet:
        enabled: true
        url-pattern: "/druid/*"
        reset-enable: false
        login-username: admin
        login-password: admin

# 安全缓存配置
security:
  cache:
    type: redis
    clean:
      enabled: true
      interval: 3600  # 1小时清理一次过期数据

  # Redis配置
  data:
    redis:
      host: localhost
      port: 6379
      password:
      database: 0
      timeout: 5000ms
      jedis:
        pool:
          max-active: 20
          max-idle: 10
          min-idle: 0
          max-wait: 5000ms

  # Kafka配置
  kafka:
    bootstrap-servers: 206.82.1.18:9092
    producer:
      retries: 3
      batch-size: 16384
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: deepreach-group
      auto-offset-reset: latest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer

deepreach:
  kafka:
    bootstrap-servers:
      - 206.82.1.18:9092
    producer:
      acks: all
      retries: 3
      batch-size: 16384
      linger-ms: 10
      buffer-memory: 33554432
      compression-type: zstd
    consumer:
      group-id: deepreach-translation-v2
      auto-offset-reset: latest
      enable-auto-commit: false
      poll-timeout: 3s
    listener:
      concurrency: 3
      ack-mode: RECORD
      idle-event-interval: 60s
      max-retries: 3
      backoff-interval: 5s
    template:
      request-timeout: 30s
      default-topic: translation-charge

  # Jackson配置
  jackson:
    time-zone: GMT+8
    date-format: yyyy-MM-dd HH:mm:ss
    serialization:
      write-dates-as-timestamps: false

# MyBatis配置
mybatis:
  mapper-locations: classpath*:mapper/*.xml
  type-aliases-package: com.deepreach.*.entity
  configuration:
    map-underscore-to-camel-case: true
    cache-enabled: true
    lazy-loading-enabled: true
    multiple-result-sets-enabled: true

# PageHelper分页配置
pagehelper:
  helper-dialect: mysql
  reasonable: true
  support-methods-arguments: true
  params: count=countSql
  auto-dialect: true
  close-conn: true
  default-count: true

# JWT配置
jwt:
  secret: deepreach2024secretkeyforjsonwebtoken
  expiration: 518400  # 144小时（单位：秒，144*60*60=518400）
  refresh-expiration: 604800  # 7天（单位：秒）

# AI配置
ai:
  openai:
    api-key: 2VyqW_PeL1hxDJHqzvYEONVWM37j1hAVZm4GV_6ukp6qUsUhm4xdgBFk2waNgFhJP1354GSt5GT3BlbkFJAn22sgR1-RArDuPkfhjdDwAKC0APAq35ZptlYfStszXq5abpzkUjOd_atkIquaOYYP9gLnMH4A
    model: gpt-3.5-turbo
    max-tokens: 1000
    temperature: 0.7
  suggestion:
    enabled: true
    endpoint: http://206.82.1.18:7808/agent/chat_with_character
    timeout-ms: 15000

# 翻译配置
translate:
  google:
    api-key: your-google-translate-api-key
  baidu:
    app-id: your-baidu-app-id
    secret: your-baidu-secret
  llm:
    openai-api-key: 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
    openai-base-url: https://api.openai.com/v1/
    qwen-api-key: sk-a9a6a4eb0c9245fca44796deb6fa6b41
    qwen-base-url: https://dashscope.aliyuncs.com/compatible-mode/v1/
    timeout-ms: 10000
    azure:
      enabled: true
      endpoint: https://cs-mhnqrz1z-eastus2.cognitiveservices.azure.com/
      api-version: 2024-02-15-preview
      deployments:
        gpt-4o: gpt-4o
        gpt-4o-mini: gpt-4o-mini
        gpt-5-nano-2025-08-07: gpt-5-nano-2025-08-07
        gpt-4.1-nano-2025-04-14: gpt-4.1-nano-2025-04-14
  billing:
    enabled: true
    topic: translation-charge
    dlq-topic: translation-charge-dlq
    description: 翻译/第三方扣费

# 阿里云ECD配置（所有环境通用默认值，若有需要可通过 profile 或数据库覆盖）
aliyun:
  ecd:
    access-key-id: LTAI5tKDpAnhZr52ttZfyTp7
    access-key-secret: yPLYk8hkTCfCW0mZdbqyQ1SzAMEmAr
    api-version: 2020-10-02
    action: GetLoginToken

message:
  sms:
    base-url: http://47.82.1.178:8000
    account-id: 49336626
    api-key: 4b3e71d9-badf-4767-85ea-90cbb5ef0944
    sender-number: 17707695953
    send-path: /sms-api/v1/49336626/send-sms/4b3e71d9-badf-4767-85ea-90cbb5ef0944/
    rate-limit-ms: 0
    timeout-ms: 10000

# 日志配置
logging:
  level:
    com.deepreach: debug
    org.springframework.security: debug
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/deepreach.log
    max-size: 10MB
    max-history: 30

# 管理端点配置
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always

file:
  storage:
    base-path: ${FILE_STORAGE_BASE_PATH:uploads}

---
# 开发环境配置
spring:
  config:
    activate:
      on-profile: dev

  # 开发环境数据源
#  datasource:
#    url: jdbc:mysql://110.42.110.38:3306/newsmspike?useUnicode=true&characterEncoding=utf8mb4&useSSL=false&serverTimezone=Asia/Shanghai&allowPublicKeyRetrieval=true&useSSL=false
#    username: newsmspike
#    password: KY7zrNkhy6kdTSjP
#    driver-class-name: com.mysql.cj.jdbc.Driver
  datasource:
    url: jdbc:mysql://206.82.1.18:33900/smspikenew?useUnicode=true&useSSL=false&serverTimezone=Asia/Shanghai&allowPublicKeyRetrieval=true&useSSL=false
    username: smspikenew
    password: LHKhXAyjcyxe4Wni


  # 云电脑数据源配置
  cloud-computer:
    datasource:
      url: jdbc:mysql://206.82.1.18:33900/cloud-computer?zeroDateTimeBehavior=convertToNull&useSSL=false&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=Asia/Shanghai
      username: root
      password: 8n2MDPdMb4qpRHYR
      driver-class-name: com.mysql.cj.jdbc.Driver

  # 开发环境Redis
  data:
    redis:
      host: localhost
      port: 6379
      database: 0

  file:
    storage:
      base-path: /uploads

---
# 测试环境配置
spring:
  config:
    activate:
      on-profile: test

  datasource:
    url: jdbc:mysql://localhost:3306/deepreach_test?useUnicode=true&useSSL=false&serverTimezone=Asia/Shanghai
---
# 生产环境配置
spring:
  config:
    activate:
      on-profile: prod

  datasource:
    url: jdbc:mysql://localhost:3306/smspikenew?useUnicode=true&useSSL=false&serverTimezone=Asia/Shanghai&allowPublicKeyRetrieval=true&useSSL=false
    username: smspikenew
    password: LHKhXAyjcyxe4Wni

  
  data:
    redis:
      host: localhost
      port: 6379
      password:
      database: 0

  kafka:
    bootstrap-servers: prod-kafka:9092

# 云电脑配置
  cloud-computer:
    datasource:
      url: jdbc:mysql://localhost:3306/cloud-computer?zeroDateTimeBehavior=convertToNull&useSSL=false&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=Asia/Shanghai
      username: root
      password: 8n2MDPdMb4qpRHYR
      driver-class-name: com.mysql.cj.jdbc.Driver
  file:
    storage:
      base-path: /home/uploads

# 生产环境日志覆盖
logging:
  level:
    com.deepreach: info
    org.springframework.security: warn
